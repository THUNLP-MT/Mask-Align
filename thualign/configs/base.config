[train]
; Initialization
initializer_gain = 1.0
initializer = uniform_unit_scaling

; Regularization
scale_l1 = 0.0
scale_l2 = 0.0

; Training
batch_size = 4096
update_cycle = 1
device_list = [0]
log_interval = 10
half = False
train_steps = 50000
initial_step = 0
warmup_steps = 4000
optimizer = Adam
adam_beta1 = 0.9
adam_beta2 = 0.98
adam_epsilon = 1e-09
adadelta_rho = 0.95
adadelta_epsilon = 1e-7
clipping = global_norm
clip_grad_norm = 0.0
learning_rate = 0.0005
initial_learning_rate = 0.0
learning_rate_schedule = linear_warmup_rsqrt_decay
learning_rate_boundaries = [0]
learning_rate_values = [0.0]
attention_dropout = 0.0
relu_dropout = 0.0
residual_dropout = 0.3
label_smoothing = 0.1

; Checkpoint Saving
keep_checkpoint_max = 20
keep_top_checkpoint_max = 5
save_summary = True
save_checkpoint_secs = 0
save_checkpoint_steps = 1000

[data]
bos = <eos>
eos = <eos>
pad = <pad>
unk = <unk>
buffer_size = 10000
max_length = 256
min_length = 1
fixed_batch_size = False
label = default

[validation]
eval_secs = 0
eval_steps = 1000
beam_size = 4
decode_batch_size = 32
decode_alpha = 0.6
decode_ratio = 1.0
decode_length = 50
top_beams = 1